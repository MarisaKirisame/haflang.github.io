{
    "title": {
        "text": {
          "headline": "Functional hardware<br/> 1936 - 2023",
          "text": "<p>A history of hardware implementations of functional languages.</p>"
        }
    },
    "events": [
        {
        "media": {
          "url": "https://upload.wikimedia.org/wikipedia/en/a/a6/Alonzo_Church.jpg",
          "caption": "Alonzo Church."
        },
        "start_date": {
          "month": "04",
          "year": "1936"
        },
        "text": {
          "headline": "The Lambda Calculus",
            "text": "<p>American mathematician Alonzo Church proposed a model of computation called the untyped lambda calculus.<br>\"An Unsolvable Problem of Elementary Number Theory\", American Journal of Mathematics.<br><a href=\"https://doi.org/10.2307%2F2371045\">https://doi.org/10.2307%2F2371045</a></p>"
        }
        },
      {
        "media": {
            "url": "/images/fp-history/backus-1978.png",
            "caption": "John Backus",
          "credit": "Communications of the ACM."
        },
        "start_date": {
          "month": "08",
          "year": "1978"
        },
          "text": {
            "text": "<p><q>A new class of computing systems uses the functional programming style both in its programming language and in its state transition rules. Unlike von Neumann languages, these systems have semantics loosely coupled to states—only one state transition occurs per major computation.</q><br><a href=\"https://doi.org/10.1145/359576.359579\">https://doi.org/10.1145/359576.359579</a></p>"
        }
      },
      {
        "media": {
          "url": "/images/fp-history/keller-1978.png",
          "caption": "Compiling function closures",
          "credit": "Technical Report UUCS-78-105, University of Utah."
        },
        "start_date": {
          "month": "10",
          "year": "1978"
        },
        "text": {
          "headline": "An Architecture for a Loosely-Coupled Parallel Processor",
            "text": "<p>Executes demand-driven applicative LISP code. Presents an architecture for a large (e.g. 1,000 processor) parallel computer. Locality of task allocation and communication is a key objective of the machine. Opportunities for concurrency arise in the parallel evaluation of arguments to strict operators, i.e . those known to require evaluation of their full set of arguments.<br><a href=\"https://collections.lib.utah.edu/ark:/87278/s6g73z2w\">https://collections.lib.utah.edu/ark:/87278/s6g73z2w</a></p>"
        }
      },
      {
        "media": {
          "url": "/images/fp-history/david_turner.jpg",
          "caption": "David Turner"
        },
        "start_date": {
          "month": "01",
          "year": "1979"
        },
        "text": {
          "headline": "A new implementation technique for applicative languages",
            "text": "<p>David Turner demonstrated with SASL (1975), and later Miranda (1986), that compiling functional code to simple S K combinators had practical application for efficient language interpreters.<br><a href=\"https://doi.org/10.1002/spe.4380090105\">https://doi.org/10.1002/spe.4380090105</a></p>"
        }
      },
      {
        "media": {
          "url": "/images/fp-history/mago-1979.png",
            "caption": "tree-structured network of identical cells",
            "credit": "US Patent - Cellular Network of Processors"
        },
        "start_date": {
          "month": "10",
          "year": "1979"
        },
        "text": {
          "headline": "A network of microprocessors to execute reduction languages",
            "text": "<p>Building on Backus's work, Gyula Mago presents a cellular processor architecture capable of directly and efficiently executing reduction languages. The processor consists of two interconnected networks of microprocessors, one of which is a linear array of identical cells, and the other a tree-structured network of identical cells.<br><a href=\"https://doi.org/10.1007/BF00995174\">https://doi.org/10.1007/BF00995174</a></p>"
        }
      },
      {
        "media": {
          "url": "/images/fp-history/skim.png",
          "caption": "SKIM Machine Block Diagram"
        },
        "start_date": {
          "month": "08",
          "day": "25",
          "year": "1980"
        },
        "text": {
          "headline": "SKIM - The S, K, I reduction machine",
            "text": "<p>Building on Turner's abstract machine for S K combinators, SKIM is a computer built to explore fine grained combinators as a machine language, and use of hardware to provide direct support for high level pure functional languages. Its hardware design stresses simplicity.<br><a href=\"https://doi.org/10.1145/800087.802798\">https://doi.org/10.1145/800087.802798</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/tolle-1981.png",
          "caption": "Partitioning inner-most applications into into a tree network",
          "credit": "ACM Programming Languages and Computer Architecture"
        },
        "start_date": {
          "month": "10",
          "year": "1981"
        },
        "text": {
          "headline": "Implanting FFP trees in binary trees: An architectural proposal",
            "text": "<p>Other researchers continued to extend Magó's tree-based cellular computer. Donald Tolle proposed an architecture that he claimed had advantages over Magó's machine in terms of simplicity, flexibility of functional operators and potential for more parallelism.<br><a href=\"https://doi.org/10.1145/800223.806770\">https://doi.org/10.1145/800223.806770</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/alice-architecture.png",
          "caption": "ALICE abstract architecture",
          "credit": "ACM Programming Languages and Computer Architecture"
        },
        "start_date": {
          "month": "10",
          "year": "1981"
        },
        "text": {
          "headline": "ALICE a multi-processor reduction machine for the parallel evaluation CF applicative languages",
            "text": "<p>A highly modular machine architecture for the parallel evaluation of a variety of applicative languages. The papers compares with related architectures including dataflow, string reduction and tree machines.<br><a href=\"https://doi.org/10.1145/800223.806764\">https://doi.org/10.1145/800223.806764</a></p>"
        }
      },
        {
        "start_date": {
          "month": "10",
          "year": "1981"
        },
        "text": {
          "headline": "Executing functional programs on a virtual tree of processors",
            "text": "<p>Warren Burton and Ronan Sleep mapped Turner's SASL language to their Zero Assignment Parallel Processor (ZAPP) at the univerity of East Anglia. They presented a simple concurrency model for executing <q>process trees</q>. Their FPCA 1981 paper: <q>Many potential users say 'Applicative languages are great to program in - they really speed up software development. But I have to reprogram in FORTRAN to get a speed I can use.'. We aim to considerably reduce the force of this argument by explofting the natural parallelism in an applicative language</q>.<br><a href=\"https://doi.org/10.1145/800223.806778\">https://doi.org/10.1145/800223.806778</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/moor-1982-hope.png",
          "caption": "Append function in HOPE compiled to CTL for the ALICE machine",
          "credit": "ACM SIGPLAN Notes"
        },
        "start_date": {
          "month": "06",
          "year": "1982"
        },
        "text": {
          "headline": "An applicative compiler for a parallel machine",
            "text": "<p>Work on evaluating the ALICE machine continued. This paper presents a compiler from HOPE to Compiler Target Language (CTL) for the ALICE simulator. Performance was quite slow: 5-10 minutes for 20 lines of HOPE, though extensions to HOPE and the compiler to exploit parallelism on ALICE are described.<br><a href=\"https://doi.org/10.1145/872726.807002\">https://doi.org/10.1145/872726.807002</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/john-hughes.jpg",
          "caption": "John Hughes invented super-combinators for efficient language implementation",
          "credit": "<a href=\"https://www.cse.chalmers.se/~rjmh/\">https://www.cse.chalmers.se/~rjmh/</a>"
        },
        "start_date": {
          "month": "08",
          "year": "1982"
        },
        "text": {
          "headline": "Super-combinators a new implementation method for applicative languages",
            "text": "<p>Efforts so far were based on combinatory logic (<a href=\"https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/abs/haskell-b-curry-and-robert-feys-combinatory-logic-volume-i-with-two-sections-by-william-craig-studies-in-logic-and-the-foundations-of-mathematics-northholland-publishing-company-amsterdam1958-xvi-417-pp/ADC0261CC1D952E97468E2803D4D7721\">Curry and Feys, 1958</a>). For example, Turner compiled SASL to S K combinators (1979). With that approach, Hughes argued that (1) machine code was far removed from the program, (2) compilation was slow, (3) execution was broken into many very small fine-grained steps. Hughes proposed super-combinators to overcome these problems.<br><a href=\"https://doi.org/10.1145/800068.802129\">https://doi.org/10.1145/800068.802129</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/traub-1985.png",
            "caption": "Parallel Graph Reduction Machine - design hierarchy",
          "credit": "ACM SIGARCH Computer Architecture News"
        },
        "start_date": {
          "month": "06",
          "year": "1985"
        },
        "text": {
          "headline": "An abstract parallel graph reduction machine",
            "text": "<p>Presents a systematic approach to the study of parallel graph reduction machines. Proposes an abstract parallel graph reduction architecture that is independent of the base language and communication network chosen for an actual implementation.<br><a href=\"https://doi.org/10.1145/327070.328253\">https://doi.org/10.1145/327070.328253</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/odonnell-1985.png",
          "caption": "Associative Aggregate Representation",
          "credit": "Springer Programming Languages and Computer Architecture"
        },
        "start_date": {
          "month": "09",
          "year": "1985"
        },
        "text": {
          "headline": "An architecture that efficiently updates associative aggregates in applicative programming languages",
            "text": "<p>Data structures in pure languages are expensive to maintain. Implementations often created complete copies of data structures when one element was updated. John O'Donnell proposed a solution with <q>associative aggregate</q> data structures and an <q>Associate Aggregate Machine</q> hardware memory design, with a linear sequence of cells forming a shift register that supported efficient insertion and deletion.<br><a href=\"https://doi.org/10.1007/3-540-15975-4_36\">https://doi.org/10.1007/3-540-15975-4_36</a></p>"
        }
      },
      {
        "start_date": {
          "year": "1985"
        },
        "text": {
          "headline": "Cobweb — A combinator reduction architecture",
          "text": "<p>A family of machines called COBWEB. The first machine employs normal order reduction to evaluate pure functional programs. The next machine uses a parallel reduction strategy. Later iterations of the architecture supported more sophisticated combinator reduction facilities.<br><a href=\"https://doi.org/10.1007/3-540-15975-4_32\">https://doi.org/10.1007/3-540-15975-4_32</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/wise-perlis.png",
            "caption": "David Wise meets Alan Perlis",
            "credit": "<a href=\"https://legacy.cs.indiana.edu/~dswise/\">https://legacy.cs.indiana.edu/~dswise/</a>"
        },
        "start_date": {
          "year": "1985"
        },
        "text": {
            "headline": "Garbage collection in hardware",
            "text": "<p>Researchers explored hardware mechanisms for efficient garbage collection, including David Wise who published <q>Design for a multiprocessing heap with on-board reference counting</q> at FPCA 1985. Wise met Alan Perlis, head of Maths, when he was a freshman. Wise became an ACM Fellow in 2007, and Alan Perlis became the first recipient of the Turing Award.<br><a href=\"https://doi.org/10.1007/3-540-15975-4_43\">https://doi.org/10.1007/3-540-15975-4_43</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/p-combinator-1986.png",
            "caption": "Two new <B>P</B> combinators for parallelism appears in ESOP 1986.",
          "credit": "<a href=\"https://doi.org/10.1007/3-540-16442-1_7\">https://doi.org/10.1007/3-540-16442-1_7</a>"
        },
        "start_date": {
          "month": "03",
          "year": "1986"
        },
        "text": {
            "headline": "A safe approach to parallel combinator reduction"
        }
      },
        {
        "start_date": {
          "month": "06",
          "year": "1986"
        },
        "text": {
            "headline": "Towards a parallel architecture for functional languages",
            "text": "<p>Presents findings of the 18 month Subproject B project on parallel architectures for functional languages, at the GEC Hirst Research Centre in Middlesex. With a focus on COBWEB (1985), they implemented Hankin's <B>P</B> combinator in their hardware for parallelism.<br><a href=\"https://doi.org/10.1007/3-540-18203-9_7\">https://doi.org/10.1007/3-540-18203-9_7</a></p>"
        }
      },
        {
        "start_date": {
          "year": "1987"
        },
        "text": {
            "headline": "Too much parallelism",
            "text": "<p>The fine-grained <B>P</B> combinator and coarse-grained approaches offered huge promise for parallel functional languages. However, architectures had limits on how much parallelism they could support. This impacted the ALICE project for functional languages. But it was also observed in other computing domains, at <a href=\"http://csg.csail.mit.edu/pubs/memos/Memo-257/Memo-257.pdf\">MIT</a>, for the <a href=\"https://doi.org/10.1007/3-540-18317-5_6\">Flagship re-write rule machine</a>, and in Japanese dataflow projects <a href=\"https://doi.org/10.1145/17356.17383\">Sigma-1</a>, <a href=\"https://doi.org/10.1145/17356.17358\">DFM</a> and <a href=\"https://doi.org/10.1145/17356.17373\">PIM-D</a>.</p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/manchester-dataflow-computer.png",
          "caption": "Manchester Dataflow Computer",
            "credit": "Communications of the ACM, <a href=\"https://doi.org/10.1145/2465.2468\">January 1985</a>"
        },
        "start_date": {
          "month": "09",
          "year": "1987"
        },
        "text": {
          "headline": "Control of parallelism in the Manchester dataflow machine",
            "text": "<p>The solution to the <q>too much parallelism</q> problem in the Manchester Dataflow Machine was coarse-grained, process-based throttling of parallelism.<br><a href=\"https://doi.org/10.1007/3-540-15975-4_36\">https://doi.org/10.1007/3-540-15975-4_36</a></p>"
        }
      },
        {
        "media": {
          "url": "/images/fp-history/tim-1987.png",
          "caption": "Machine state is a function applied to arguments on the stack",
            "credit": "Springer, FPCA 1987"
        },
        "start_date": {
          "month": "09",
          "year": "1987"
        },
        "text": {
          "headline": "Tim: A simple, lazy abstract machine to execute supercombinators",
            "text": "<p>Reseachers at Cambridge took the supercombinator approach to graph reduction. Tim had three instructions: <i>Take</i> to move items from the argument stack to a frame on the heap, <i>Push</i> to push an item onto the argument stack and <i>Enter</i> to load the current frame and program counter with an item. <q>The simplicity of this machine suggests that it would not be difficult to implement as a chip.</q><br><a href=\"https://doi.org/10.1007/3-540-18317-5_3\">https://doi.org/10.1007/3-540-18317-5_3</a></p>"
        }
      },
      {
        "start_date": {
          "year": "1989"
        },
        "text": {
          "headline": "MaRS, a combinator graph reduction multiprocessor",
            "text": "<p>Modular distributed control multiprocessor for parallel graph reduction using a combinator machine language. Dedicated to the parallel execution of purely functional languages, the machine used separate specially designed processors for Reduction, Memory and Communication.<br><a href=\"https://doi.org/10.1007/3540512845_39\">https://doi.org/10.1007/3540512845_39</a></p>"
        }
      },
      {
        "start_date": {
          "month": "03",
          "day": "01",
          "year": "1992"
        },
        "text": {
          "headline": "Parallel Combinator Reduction: Some Performance Bounds",
            "text": "<p>A parallel graph reduction machine simulator that performs combinator reduction and simulates various different parallel reduction strategies. A number of functional programs are examined, and experimental results presented comparing the amount of parallelism obtainable.<br><a href=\"https://www.dcs.warwick.ac.uk/report/pdfs/cs-rr-210.pdf\">https://www.dcs.warwick.ac.uk/report/pdfs/cs-rr-210.pdf</a></p>"
        }
      }
    ]
}
